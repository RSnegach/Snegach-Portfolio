from datetime import datetime
import requests
from bs4 import BeautifulSoup
import pandas as pd
import sqlite3

def log_progress(message):
    """
    Appends a timestamped message to 'code_log.txt'
    """
    with open("code_log.txt", "a") as f:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"[{timestamp}] {message}\n")

log_progress("Program started.")

def extract():
    url = "https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")

    # Find the correct table ("By market capitalization")
    tables = soup.find_all("table", {"class": "wikitable"})
    target_table = tables[0]  # First table

    rows = target_table.find_all("tr")
    data = []

    for row in rows[1:11]:  # Skip header and get top 10 banks
        cols = row.find_all("td")
        if len(cols) >= 3:
            name = cols[1].text.strip()
            mc_usd = cols[2].text.strip().replace("\n", "").replace(",", "")
            try:
                mc_usd = float(mc_usd)
            except ValueError:
                continue  # skip rows with invalid data
            data.append([name, mc_usd])

    df = pd.DataFrame(data, columns=["Name", "MC_USD_Billion"])
    return df

df_banks = extract()
log_progress("Data extracted from Wikipedia.")

def transform(df):
    exchange_url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
    exchange_rates = pd.read_csv(exchange_url, index_col="Currency")["Rate"]

    df["MC_GBP_Billion"] = round(df["MC_USD_Billion"] * exchange_rates["GBP"], 2)
    df["MC_EUR_Billion"] = round(df["MC_USD_Billion"] * exchange_rates["EUR"], 2)
    df["MC_INR_Billion"] = round(df["MC_USD_Billion"] * exchange_rates["INR"], 2)

    return df

df_transformed = transform(df_banks)
log_progress("Data transformed using exchange rates.")

def load_to_csv(df, csv_path="./Largest_banks_data.csv"):
    df.to_csv(csv_path, index=False)
    log_progress(f"Data saved to CSV at {csv_path}.")

def load_to_db(df, db_name="Banks.db", table_name="Largest_banks"):
    try:
        conn = sqlite3.connect(db_name)
        df.to_sql(table_name, conn, if_exists='replace', index=False)
        conn.close()
        log_progress(f"Data saved to database '{db_name}' in table '{table_name}'.")
        print(f" Saved to database '{db_name}' in table '{table_name}'.")
    except Exception as e:
        log_progress(f" Error saving to database: {e}")
        print(f"Error saving to database: {e}")

load_to_csv(df_transformed)
load_to_db(df_transformed)

def run_queries(db_name="Banks.db", queries=[]):
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()

    for i, query in enumerate(queries):
        print(f"\n Query {i+1}: {query}")
        try:
            result = pd.read_sql(query, conn)
            print(result)
            log_progress(f"Query {i+1} executed successfully.")
        except Exception as e:
            print(f" Error executing query {i+1}: {e}")
            log_progress(f"Error executing query {i+1}: {e}")
    
    conn.close()
    log_progress("All queries completed.")

queries = [
    "SELECT * FROM Largest_banks LIMIT 5;",
    "SELECT Name, MC_EUR_Billion FROM Largest_banks ORDER BY MC_EUR_Billion DESC;",
    "SELECT Name FROM Largest_banks WHERE MC_INR_Billion > 30000;"
]

run_queries(queries=queries)
